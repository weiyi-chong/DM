{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM2NEuW75hDcWd5XiyjTxX5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Book 1 - Chapter 3 and Chapter 4"],"metadata":{"id":"yeWOXWCQWhvd"}},{"cell_type":"markdown","source":["##3.2.1 Train and Test Split\n","Splitting a Contrived Dataset into Train and Test Splits"],"metadata":{"id":"zqAzCAoLo0sE"}},{"cell_type":"code","source":["# Example of Splitting a Contrived Dataset into Train and Test\n","from random import seed\n","from random import randrange\n","\n","# Split a dataset into a train and test set\n","def train_test_split(dataset, split=0.60):\n","  train = list()\n","  train_size = split * len(dataset)\n","  dataset_copy = list(dataset)\n","  while len(train) < train_size:\n","    index = randrange(len(dataset_copy))\n","    train.append(dataset_copy.pop(index))\n","  return train, dataset_copy\n","\n","# test train/test split\n","seed(1)\n","dataset = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]\n","train, test = train_test_split(dataset)\n","print(train)\n","print(test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m-4FnRjcorxG","executionInfo":{"status":"ok","timestamp":1681205346394,"user_tz":-480,"elapsed":12,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"73b08140-0595-48f6-cc23-ffac67579ad9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[3], [2], [7], [1], [8], [9]]\n","[[4], [5], [6], [10]]\n"]}]},{"cell_type":"markdown","source":["##3.2.2 k-fold Cross-Validation\n","a resampling method that provides a more accurate estimate of algorithm performance. split into k groups, algo trained and evaluated k times and performance is summarized by taking mean performance score. Each group is called fold"],"metadata":{"id":"H_C6pWulpDf3"}},{"cell_type":"code","source":["# Example of Creating a Cross Validation Split\n","from random import seed\n","from random import randrange\n","\n","# Split a dataset into k folds\n","def cross_validation_split(dataset, folds=3):\n","  dataset_split = list()\n","  dataset_copy = list(dataset)\n","  fold_size = int(len(dataset) / folds)\n","  for _ in range(folds):\n","    fold = list()\n","    while len(fold) < fold_size:\n","      index = randrange(len(dataset_copy))\n","      fold.append(dataset_copy.pop(index))\n","    dataset_split.append(fold)\n","  return dataset_split\n","\n","# test cross validation split\n","seed(1)\n","dataset = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]\n","folds = cross_validation_split(dataset, 4)\n","print(folds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EW7T5_7ApDKd","executionInfo":{"status":"ok","timestamp":1681205422853,"user_tz":-480,"elapsed":354,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"4c618f37-8ea9-47dd-ebb7-5e018b108da5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[[3], [2]], [[7], [1]], [[8], [9]], [[10], [6]]]\n"]}]},{"cell_type":"markdown","source":["##4.2.1 Classification Accuracy\n","Classiffcation accuracy is a ratio of the number of correct predictions out of all predictions that\n","were made. It is often presented as a percentage between 0% for the worst possible accuracy\n","and 100% for the best possible accuracy."],"metadata":{"id":"pV21OjeHpcQV"}},{"cell_type":"code","source":["# Example of calculating classification accuracy\n","# Calculate accuracy percentage between two lists\n","def accuracy_metric(actual, predicted):\n","  correct = 0\n","  for i in range(len(actual)):\n","    if actual[i] == predicted[i]:\n","      correct += 1\n","  return correct / float(len(actual)) * 100.0\n","\n","# Test accuracy\n","actual = [0,0,0,0,0,1,1,1,1,1]\n","predicted = [0,1,0,0,0,1,0,1,1,1]\n","accuracy = accuracy_metric(actual, predicted)\n","print(accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A-SZjIt0pg1p","executionInfo":{"status":"ok","timestamp":1681205482947,"user_tz":-480,"elapsed":353,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"9f59700b-efc7-4588-d304-dd005227a4ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["80.0\n"]}]},{"cell_type":"markdown","source":["##4.2.2 Confusion Matrix\n","provides a summary of all of the predictions made compared to the expected\n","actual values. The counts of\n","predicted class values are summarized horizontally (rows), whereas the counts of actual values\n","for each class values are presented vertically (columns). A perfect set of predictions is shown as\n","a diagonal line from the top left to the bottom right of the matrix.\n","The value of a confusion matrix for classi\n","cation problems is that you"],"metadata":{"id":"u4Z3nNrMpvxM"}},{"cell_type":"code","source":["# Example of Calculating a Confusion Matrix\n","# calculate a confusion matrix\n","def confusion_matrix(actual, predicted):\n","  unique = set(actual)\n","  matrix = [list() for x in range(len(unique))]\n","  for i in range(len(unique)):\n","    matrix[i] = [0 for x in range(len(unique))]\n","  lookup = dict()\n","  for i, value in enumerate(unique):\n","    lookup[value] = i\n","  for i in range(len(actual)):\n","    x = lookup[actual[i]]\n","    y = lookup[predicted[i]]\n","    matrix[y][x] += 1\n","  return unique, matrix\n","\n","# Test confusion matrix with integers\n","actual = [0,0,0,0,0,1,1,1,1,1]\n","predicted = [0,1,1,0,0,1,0,1,1,1]\n","unique, matrix = confusion_matrix(actual, predicted)\n","print(unique)\n","print(matrix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hfR9qdS5py8R","executionInfo":{"status":"ok","timestamp":1681205518388,"user_tz":-480,"elapsed":326,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"38cb2e9e-11be-428d-c909-2534fef3294e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{0, 1}\n","[[3, 1], [2, 4]]\n"]}]},{"cell_type":"markdown","source":["Human Readable Confusion Matrix"],"metadata":{"id":"0crc1ug3qKt_"}},{"cell_type":"code","source":["# Example of Calculating and Displaying a Pretty Confusion Matrix\n","# calculate a confusion matrix\n","def confusion_matrix(actual, predicted):\n","  unique = set(actual)\n","  matrix = [list() for x in range(len(unique))]\n","  for i in range(len(unique)):\n","    matrix[i] = [0 for x in range(len(unique))]\n","  lookup = dict()\n","  for i, value in enumerate(unique):\n","    lookup[value] = i\n","  for i in range(len(actual)):\n","    x = lookup[actual[i]]\n","    y = lookup[predicted[i]]\n","    matrix[y][x] += 1\n","  return unique, matrix\n","\n","# pretty print a confusion matrix\n","def print_confusion_matrix(unique, matrix):\n","  print('(A)' + ' '.join(str(x) for x in unique))\n","  print('(P)---')\n","  for i, x in enumerate(unique):\n","    print(\"%s| %s\" % (x, ' '.join(str(x) for x in matrix[i])))\n","\n","# Test confusion matrix with integers\n","actual = [0,0,0,0,0,1,1,1,1,1]\n","predicted = [0,1,1,0,0,1,0,1,1,1]\n","unique, matrix = confusion_matrix(actual, predicted)\n","print_confusion_matrix(unique, matrix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xNQ7Nkg_qPHu","executionInfo":{"status":"ok","timestamp":1681205609944,"user_tz":-480,"elapsed":326,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"f389dd6f-3d41-4f46-f360-aefe1cfdcfc4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(A)0 1\n","(P)---\n","0| 3 1\n","1| 2 4\n"]}]},{"cell_type":"markdown","source":["##4.2.3 Mean Abslute Error\n","good first error metric to use. It is calculated as the average of the absolute\n","error values, where absolute means made positive so that they can be added together."],"metadata":{"id":"nh6IkaKZqdbs"}},{"cell_type":"code","source":["# Example of Calculating Mean Absolute Error\n","# Calculate mean absolute error\n","def mae_metric(actual, predicted):\n","  sum_error = 0.0\n","  for i in range(len(actual)):\n","    sum_error += abs(predicted[i] - actual[i])\n","  return sum_error / float(len(actual))\n","\n","# Test RMSE\n","actual = [0.1, 0.2, 0.3, 0.4, 0.5]\n","predicted = [0.11, 0.19, 0.29, 0.41, 0.5]\n","mae = mae_metric(actual, predicted)\n","print(mae)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mqV7p7XLqgBy","executionInfo":{"status":"ok","timestamp":1681205650086,"user_tz":-480,"elapsed":6,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"016e44b0-bb2e-40d5-b7ae-75ec832c7ad9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.007999999999999993\n"]}]},{"cell_type":"markdown","source":["##4.2.4 Root Mean Squared Error\n","RMSE is calculated as the\n","square root of the mean of the squared di\n","erences between actual outcomes and predictions.\n","Squaring each error forces the values to be positive, and the square root of the mean squared\n","error returns the error metric back to the original units for comparison"],"metadata":{"id":"m0lt9ZE5qnG0"}},{"cell_type":"code","source":["# Example of Calculating the Root Mean Squared Error\n","from math import sqrt\n","\n","# Calculate root mean squared error\n","def rmse_metric(actual, predicted):\n","  sum_error = 0.0\n","  for i in range(len(actual)):\n","    prediction_error = predicted[i] - actual[i]\n","    sum_error += (prediction_error ** 2)\n","  mean_error = sum_error / float(len(actual))\n","  return sqrt(mean_error)\n","\n","# Test RMSE\n","actual = [0.1, 0.2, 0.3, 0.4, 0.5]\n","predicted = [0.11, 0.19, 0.29, 0.41, 0.5]\n","rmse = rmse_metric(actual, predicted)\n","print(rmse)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RxABwsQHqq8m","executionInfo":{"status":"ok","timestamp":1681205699712,"user_tz":-480,"elapsed":328,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"14eba7f0-6619-4f71-ee94-0d64fda944b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.00894427190999915\n"]}]},{"cell_type":"markdown","source":["#Book 2- Chapter 9 and Chapter 10"],"metadata":{"id":"UGDtKrS3WgQJ"}},{"cell_type":"markdown","source":["##9.2 Split into train and test sets\n","ideal for large datasets (millions of\n","records) where there is strong evidence that both splits of the data are representative of the\n","underlying problem.\n","- advantage, speed = useful to use this approach when the algorithm you are investigating is slow to train.\n","- disadvantage, high variance - that differences in the training and test dataset can result in meaningful\n","differences in the estimate of accuracy. \n"],"metadata":{"id":"j1KS7gxCWsot"}},{"cell_type":"code","source":["# Evaluate using a train and a test set\n","from pandas import read_csv\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","filename = 'pima-indians-diabetes.csv'\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = read_csv(filename, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","test_size = 0.33\n","seed = 7\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n","model = LogisticRegression(solver='liblinear')\n","model.fit(X_train, Y_train)\n","result = model.score(X_test, Y_test)\n","print(\"Accuracy: %.3f%%\" % (result*100.0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"09A57a-LWrzR","executionInfo":{"status":"ok","timestamp":1681703981590,"user_tz":-480,"elapsed":2358,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"c135ef0d-aef4-4390-fd9d-b3d01f95ea76"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 75.591%\n"]}]},{"cell_type":"markdown","source":["## 9.3 K-fold Cross Validation\n","Cross-validation is an approach that you can use to estimate the performance of a machine\n","learning algorithm with less variance than a single train-test set split. It works by splitting\n","the dataset into k-parts"],"metadata":{"id":"_k6k82_sXD9d"}},{"cell_type":"code","source":["from pandas import read_csv\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","\n","filename = 'pima-indians-diabetes.csv'\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = read_csv(filename, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","\n","kfold = KFold(n_splits=10, shuffle=True, random_state=7)\n","model = LogisticRegression(solver='liblinear')\n","results = cross_val_score(model, X, Y, cv=kfold)\n","\n","print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nqI6RTgiXGvj","executionInfo":{"status":"ok","timestamp":1681704304302,"user_tz":-480,"elapsed":413,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"b0cea095-b61f-4ac3-f02a-c9b340142765"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 77.086% (5.091%)\n"]}]},{"cell_type":"markdown","source":["##9.4 Leave One Out Cross Validation"],"metadata":{"id":"fP6ipkzXXNwQ"}},{"cell_type":"code","source":["# Evaluate using Leave One Out Cross Validation\n","from pandas import read_csv\n","from sklearn.model_selection import LeaveOneOut\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","filename = 'pima-indians-diabetes.csv'\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = read_csv(filename, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","loocv = LeaveOneOut()\n","model = LogisticRegression(solver='liblinear')\n","results = cross_val_score(model, X, Y, cv=loocv)\n","print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r7U6z5LGXScn","executionInfo":{"status":"ok","timestamp":1681704173314,"user_tz":-480,"elapsed":7291,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"a6fac01c-61f0-4f7e-e9a0-847f411320ca"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 76.823% (42.196%)\n"]}]},{"cell_type":"markdown","source":["##9.5 Repeated Random Test-Train Splits\n","This has the speed of using a train/test split and\n","the reduction in variance in the estimated performance of k-fold cross-validation."],"metadata":{"id":"sIB2JjcbXYMs"}},{"cell_type":"code","source":["# Evaluate using Shuffle Split Cross Validation\n","from pandas import read_csv\n","from sklearn.model_selection import ShuffleSplit\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","filename = 'pima-indians-diabetes.csv'\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = read_csv(filename, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","n_splits = 10\n","test_size = 0.33\n","seed = 7\n","kfold = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=seed)\n","model = LogisticRegression(solver='liblinear')\n","results = cross_val_score(model, X, Y, cv=kfold)\n","print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w9kIf6paXchM","executionInfo":{"status":"ok","timestamp":1681704184289,"user_tz":-480,"elapsed":414,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"2149bab6-762f-4d7e-bdcb-4cdf4ec8aa17"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 76.535% (1.691%)\n"]}]},{"cell_type":"markdown","source":["##10.2 Classification Metrics"],"metadata":{"id":"1Rqd0VudZ9VD"}},{"cell_type":"markdown","source":["###10.2.1 Classification Accuracy\n","The number of correct predictions made as a ratio of all predictions\n","made."],"metadata":{"id":"98EKVjSfaDLR"}},{"cell_type":"code","source":["# Cross Validation Classification Accuracy\n","from pandas import read_csv\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","filename = 'pima-indians-diabetes.csv'\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = read_csv(filename, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","kfold = KFold(n_splits=10, shuffle=True,  random_state=7)\n","model = LogisticRegression(solver='liblinear')\n","scoring = 'accuracy'\n","results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n","print(\"Accuracy: %.3f (%.3f)\" % (results.mean(), results.std()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GM81Ka_RaOe_","executionInfo":{"status":"ok","timestamp":1681704714208,"user_tz":-480,"elapsed":588,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"8f00b8b9-b446-476d-d5df-8dc72b9b3163"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.771 (0.051)\n"]}]},{"cell_type":"markdown","source":["###10.2.2 Logarithmic Loss\n","A performance metric for evaluating the predictions of probabilities of membership to a given class."],"metadata":{"id":"xo0WaBiAaZyh"}},{"cell_type":"code","source":["# Cross Validation Classification LogLoss\n","from pandas import read_csv\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","filename = 'pima-indians-diabetes.csv'\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = read_csv(filename, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","kfold = KFold(n_splits=10, shuffle=True, random_state=7)\n","model = LogisticRegression(solver='liblinear')\n","scoring = 'neg_log_loss'\n","results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n","print(\"Logloss: %.3f (%.3f)\" % (results.mean(), results.std()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kYMrfP5xajiy","executionInfo":{"status":"ok","timestamp":1681704777735,"user_tz":-480,"elapsed":340,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"1e2cf818-8da7-422b-e302-659e4c29788a"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Logloss: -0.494 (0.042)\n"]}]},{"cell_type":"markdown","source":["###10.2.3 Area Under ROC Curve\n","A performance metric for binary classiffcation\n","problems. The AUC represents a model's ability to discriminate between positive and negative\n","classes. An area of 1.0 represents a model that made all predictions perfectly.\n","- Sensitivity (Recall) is the true positive rate. It is the number of instances from the positive (first) class that were actually predicted correctly.\n","- Specificity is also called the true negative rate. Is the number of instances from the negative (second) class that were actually predicted correctly."],"metadata":{"id":"bMEcw1BWapEM"}},{"cell_type":"code","source":["# Cross Validation Classification ROC AUC\n","from pandas import read_csv\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","filename = 'pima-indians-diabetes.csv'\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = read_csv(filename, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","kfold = KFold(n_splits=10, shuffle=True, random_state=7)\n","model = LogisticRegression(solver='liblinear')\n","scoring = 'roc_auc'\n","results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n","print(\"AUC: %.3f (%.3f)\" % (results.mean(), results.std()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wr52krZbasdQ","executionInfo":{"status":"ok","timestamp":1681704930538,"user_tz":-480,"elapsed":471,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"cd74a60d-a375-436d-a818-865f5a1a58b6"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["AUC: 0.826 (0.050)\n"]}]},{"cell_type":"markdown","source":["###10.2.4 Confusion Matrix\n","Handy presentation of the accuracy of a model with two or more classes. The table presents predictions on the x-axis and true outcomes on the y-axis."],"metadata":{"id":"e7pfRG1GbO0f"}},{"cell_type":"code","source":["# Cross Validation Classification Confusion Matrix\n","from pandas import read_csv\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import confusion_matrix\n","filename = 'pima-indians-diabetes.csv'\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = read_csv(filename, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","test_size = 0.33\n","seed = 7\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n","model = LogisticRegression(solver='liblinear')\n","model.fit(X_train, Y_train)\n","predicted = model.predict(X_test)\n","matrix = confusion_matrix(Y_test, predicted)\n","print(matrix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4SftGhlxbZSu","executionInfo":{"status":"ok","timestamp":1681705003999,"user_tz":-480,"elapsed":609,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"f0bded8c-af4d-49a8-b4ca-5daddf7da5ca"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[[141  21]\n"," [ 41  51]]\n"]}]},{"cell_type":"markdown","source":["###10.2.5 Classification Report\n","The classification report() function displays the precision, recall, F1-score and support for each\n","class."],"metadata":{"id":"X6AKMr9YbgHb"}},{"cell_type":"code","source":["# Cross Validation Classification Report\n","from pandas import read_csv\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","filename = 'pima-indians-diabetes.csv'\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = read_csv(filename, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","test_size = 0.33\n","seed = 7\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n","random_state=seed)\n","model = LogisticRegression(solver='liblinear')\n","model.fit(X_train, Y_train)\n","predicted = model.predict(X_test)\n","report = classification_report(Y_test, predicted)\n","print(report)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I4DY9iMLbf0D","executionInfo":{"status":"ok","timestamp":1681705061451,"user_tz":-480,"elapsed":618,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"9fabdb27-61f2-4ce4-c34b-e29319bbf60e"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","         0.0       0.77      0.87      0.82       162\n","         1.0       0.71      0.55      0.62        92\n","\n","    accuracy                           0.76       254\n","   macro avg       0.74      0.71      0.72       254\n","weighted avg       0.75      0.76      0.75       254\n","\n"]}]},{"cell_type":"markdown","source":["##10.3 Regression Metrics"],"metadata":{"id":"AZqyA6V7buEX"}},{"cell_type":"markdown","source":["###10.3.1 Mean Absolute Error\n","The Mean Absolute Error (or MAE) is the sum of the absolute differences between predictions\n","and actual values. It gives an idea of how wrong the predictions were.\n"],"metadata":{"id":"_8mhLsR5by-N"}},{"cell_type":"code","source":["# Cross Validation Regression MAE\n","from pandas import read_csv\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LinearRegression\n","filename = 'housing.csv'\n","names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', \n","         'LSTAT', 'MEDV']\n","dataframe = read_csv(filename, delim_whitespace=True, names=names)\n","array = dataframe.values\n","X = array[:,0:13]\n","Y = array[:,13]\n","kfold = KFold(n_splits=10, shuffle = True, random_state=7)\n","model = LinearRegression()\n","scoring = 'neg_mean_absolute_error'\n","results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n","print(\"MAE: %.3f (%.3f)\" % (results.mean(), results.std()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uapT6eL6b4Jx","executionInfo":{"status":"ok","timestamp":1681705246777,"user_tz":-480,"elapsed":497,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"664eff0c-3c51-4a3b-f2e9-8a9e0a0bd69f"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["MAE: -3.387 (0.667)\n"]}]},{"cell_type":"markdown","source":["###10.3.2 Mean Squared Error\n","The Mean Squared Error (or MSE) is much like the mean absolute error in that it provides a\n","gross idea of the magnitude of error."],"metadata":{"id":"bNDR_TUaccXe"}},{"cell_type":"code","source":["# Cross Validation Regression MSE\n","from pandas import read_csv\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LinearRegression\n","filename = 'housing.csv'\n","names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n","'B', 'LSTAT', 'MEDV']\n","dataframe = read_csv(filename, delim_whitespace=True, names=names)\n","array = dataframe.values\n","X = array[:,0:13]\n","Y = array[:,13]\n","kfold = KFold(n_splits=10, shuffle=True, random_state=7)\n","model = LinearRegression()\n","scoring = 'neg_mean_squared_error'\n","results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n","print(\"MSE: %.3f (%.3f)\" % (results.mean(), results.std()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xWlQLnQ0chBq","executionInfo":{"status":"ok","timestamp":1681705327491,"user_tz":-480,"elapsed":528,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"1b1090ec-bed1-4f8f-cff5-ff7b8ecd0bb8"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["MSE: -23.747 (11.143)\n"]}]},{"cell_type":"markdown","source":["###10.3.3 R-squared Metric\n","Provides an indication of the goodness of fit of a set of predictions to the actual values."],"metadata":{"id":"ZGi5bCSjcuuU"}},{"cell_type":"code","source":["# Cross Validation Regression R^2\n","from pandas import read_csv\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LinearRegression\n","filename = 'housing.csv'\n","names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n","'B', 'LSTAT', 'MEDV']\n","dataframe = read_csv(filename, delim_whitespace=True, names=names)\n","array = dataframe.values\n","X = array[:,0:13]\n","Y = array[:,13]\n","kfold = KFold(n_splits=10, shuffle=True, random_state=7)\n","model = LinearRegression()\n","scoring = 'r2'\n","results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n","print(\"R^2: %.3f (%.3f)\" % (results.mean(), results.std()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RIiezDRvcuU7","executionInfo":{"status":"ok","timestamp":1681705404479,"user_tz":-480,"elapsed":408,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"a74fff45-14ff-4a16-d31f-69cd8106f37b"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["R^2: 0.718 (0.099)\n"]}]}]}