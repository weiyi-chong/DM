{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyONhG/6Kr3/BBXB3sPFIVv4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Naive Bayes\n"],"metadata":{"id":"YkzARXcvalU4"}},{"cell_type":"markdown","source":["### Separate By Class\n","- assumes that the last column in each row is the class value\n","- Running the example sorts observations in the dataset by their class value, then prints the class value followed by all identified records.\n","- separate_by_class() function to separate a dataset into rows by class"],"metadata":{"id":"kX-0-WRiazwF"}},{"cell_type":"code","source":["# Example of separating data by class value\n","# Split the dataset by class values, returns a dictionary\n","def separate_by_class(dataset):\n","  separated = dict()\n","  for i in range(len(dataset)):\n","    vector = dataset[i]\n","    class_value = vector[-1]\n","    if (class_value not in separated):\n","      separated[class_value] = list()\n","    separated[class_value].append(vector)\n","  return separated\n","\n","# Test separating data by class\n","dataset = [[3.393533211,2.331273381,0],\n","  [3.110073483,1.781539638,0],\n","  [1.343808831,3.368360954,0],\n","  [3.582294042,4.67917911,0],\n","  [2.280362439,2.866990263,0],\n","  [7.423436942,4.696522875,1],\n","  [5.745051997,3.533989803,1],\n","  [9.172168622,2.511101045,1],\n","  [7.792783481,3.424088941,1],\n","  [7.939820817,0.791637231,1]]\n","separated = separate_by_class(dataset)\n","for label in separated:\n","  print(label)\n","  for row in separated[label]:\n","    print(row)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nCSEGOJ9alCO","executionInfo":{"status":"ok","timestamp":1682997418112,"user_tz":-480,"elapsed":339,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"2e2681c3-a457-40ab-ebba-5fabb460d94e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","[3.393533211, 2.331273381, 0]\n","[3.110073483, 1.781539638, 0]\n","[1.343808831, 3.368360954, 0]\n","[3.582294042, 4.67917911, 0]\n","[2.280362439, 2.866990263, 0]\n","1\n","[7.423436942, 4.696522875, 1]\n","[5.745051997, 3.533989803, 1]\n","[9.172168622, 2.511101045, 1]\n","[7.792783481, 3.424088941, 1]\n","[7.939820817, 0.791637231, 1]\n"]}]},{"cell_type":"markdown","source":["### Summarize Dataset\n","- summarize dataset() function to calculate summary statistics for each column\n"],"metadata":{"id":"1xnLe7TXb39v"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D0b9fSVTadoC","executionInfo":{"status":"ok","timestamp":1682997423429,"user_tz":-480,"elapsed":421,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"800356cb-96e8-4157-8812-4bb4239241d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["[(5.178333386499999, 2.7665845055177263, 10), (2.9984683241, 1.218556343617447, 10)]\n"]}],"source":["# Example of summarizing a dataset\n","from math import sqrt\n","\n","# Calculate the mean of a list of numbers\n","def mean(numbers):\n","  return sum(numbers)/float(len(numbers))\n","\n","# Calculate the standard deviation of a list of numbers\n","def stdev(numbers):\n","  avg = mean(numbers)\n","  variance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\n","  return sqrt(variance)\n","\n","# Calculate the mean, stdev and count for each column in a dataset\n","def summarize_dataset(dataset):\n","  summaries = [(mean(column), stdev(column), len(column)) for column in zip(*dataset)]\n","  del(summaries[-1])\n","  return summaries\n","\n","# Test summarizing a dataset\n","dataset = [[3.393533211,2.331273381,0],\n","  [3.110073483,1.781539638,0],\n","  [1.343808831,3.368360954,0],\n","  [3.582294042,4.67917911,0],\n","  [2.280362439,2.866990263,0],\n","  [7.423436942,4.696522875,1],\n","  [5.745051997,3.533989803,1],\n","  [9.172168622,2.511101045,1],\n","  [7.792783481,3.424088941,1],\n","  [7.939820817,0.791637231,1]]\n","summary = summarize_dataset(dataset)\n","print(summary)"]},{"cell_type":"markdown","source":["### Summarize Data By Class\n","- Put separate_by_class() and summarize_dataset() together and summarize the columns in the dataset organized by class values -> summarize_by_class()\n","- The dataset is first split by class, then statistics are calculated on each subset. The results in the\n","form of a list of tuples of statistics are then stored in a dictionary by their class value."],"metadata":{"id":"L9PeaNxdcnXx"}},{"cell_type":"code","source":["# Example of summarizing data by class value\n","from math import sqrt\n","# Split the dataset by class values, returns a dictionary\n","def separate_by_class(dataset):\n","  separated = dict()\n","  for i in range(len(dataset)):\n","    vector = dataset[i]\n","    class_value = vector[-1]\n","    if (class_value not in separated):\n","      separated[class_value] = list()\n","    separated[class_value].append(vector)\n","  return separated\n","\n","# Calculate the mean of a list of numbers\n","def mean(numbers):\n","  return sum(numbers)/float(len(numbers))\n","\n","# Calculate the standard deviation of a list of numbers\n","def stdev(numbers):\n","  avg = mean(numbers)\n","  variance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\n","  return sqrt(variance)\n","\n","# Calculate the mean, stdev and count for each column in a dataset\n","def summarize_dataset(dataset):\n","  summaries = [(mean(column), stdev(column), len(column)) for column in zip(*dataset)]\n","  del(summaries[-1])\n","  return summaries\n","\n","# Split dataset by class then calculate statistics for each row\n","def summarize_by_class(dataset):\n","  separated = separate_by_class(dataset)\n","  summaries = dict()\n","  for class_value, rows in separated.items():\n","    summaries[class_value] = summarize_dataset(rows)\n","  return summaries\n","\n","# Test summarizing by class\n","dataset = [[3.393533211,2.331273381,0],\n","  [3.110073483,1.781539638,0],\n","  [1.343808831,3.368360954,0],\n","  [3.582294042,4.67917911,0],\n","  [2.280362439,2.866990263,0],\n","  [7.423436942,4.696522875,1],\n","  [5.745051997,3.533989803,1],\n","  [9.172168622,2.511101045,1],\n","  [7.792783481,3.424088941,1],\n","  [7.939820817,0.791637231,1]]\n","summary = summarize_by_class(dataset)\n","for label in summary:\n","  print(label)\n","  for row in summary[label]:\n","    print(row)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w1lDdNHdcqYo","executionInfo":{"status":"ok","timestamp":1682997437567,"user_tz":-480,"elapsed":430,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"9effade7-d78b-4a24-b65e-b2b8fe354de3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","(2.7420144012, 0.9265683289298018, 5)\n","(3.0054686692, 1.1073295894898725, 5)\n","1\n","(7.6146523718, 1.2344321550313704, 5)\n","(2.9914679790000003, 1.4541931384601618, 5)\n"]}]},{"cell_type":"markdown","source":["### Gaussian Probability Density Function"],"metadata":{"id":"tE9ZEvI3dvzw"}},{"cell_type":"code","source":["# Example of Gaussian PDF\n","from math import sqrt\n","from math import pi\n","from math import exp\n","\n","# Calculate the Gaussian probability distribution function for x\n","def calculate_probability(x, mean, stdev):\n","  exponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n","  return (1 / (sqrt(2 * pi) * stdev)) * exponent\n","\n","# Test Gaussian PDF\n","print(calculate_probability(1.0, 1.0, 1.0))\n","print(calculate_probability(2.0, 1.0, 1.0))\n","print(calculate_probability(0.0, 1.0, 1.0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lo2JU2jQd2KJ","executionInfo":{"status":"ok","timestamp":1682997525423,"user_tz":-480,"elapsed":320,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"f5bc60b6-e9c9-418e-ced2-8b2a9913912c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["0.3989422804014327\n","0.24197072451914337\n","0.24197072451914337\n"]}]},{"cell_type":"markdown","source":["###Class Probability\n","- calculates the summary statistics by class for the training dataset, then uses these statistics to\n","calculate the probability of the first record belonging to each class."],"metadata":{"id":"DcmCQgs3eFJk"}},{"cell_type":"code","source":["# Example of calculating class probabilities\n","from math import sqrt\n","from math import pi\n","from math import exp\n","\n","# Split the dataset by class values, returns a dictionary\n","def separate_by_class(dataset):\n","  separated = dict()\n","  for i in range(len(dataset)):\n","    vector = dataset[i]\n","    class_value = vector[-1]\n","    if (class_value not in separated):\n","      separated[class_value] = list()\n","    separated[class_value].append(vector)\n","  return separated\n","\n","# Calculate the mean of a list of numbers\n","def mean(numbers):\n","  return sum(numbers)/float(len(numbers))\n","\n","# Calculate the standard deviation of a list of numbers\n","def stdev(numbers):\n","  avg = mean(numbers)\n","  variance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\n","  return sqrt(variance)\n","\n","# Calculate the mean, stdev and count for each column in a dataset\n","def summarize_dataset(dataset):\n","  summaries = [(mean(column), stdev(column), len(column)) for column in zip(*dataset)]\n","  del(summaries[-1])\n","  return summaries\n","\n","# Split dataset by class then calculate statistics for each row\n","def summarize_by_class(dataset):\n","  separated = separate_by_class(dataset)\n","  summaries = dict()\n","  for class_value, rows in separated.items():\n","    summaries[class_value] = summarize_dataset(rows)\n","  return summaries\n","\n","# Calculate the Gaussian probability distribution function for x\n","def calculate_probability(x, mean, stdev):\n","  exponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n","  return (1 / (sqrt(2 * pi) * stdev)) * exponent\n","\n","# Calculate the probabilities of predicting each class for a given row\n","def calculate_class_probabilities(summaries, row):\n","  total_rows = sum([summaries[label][0][2] for label in summaries])\n","  probabilities = dict()\n","  for class_value, class_summaries in summaries.items():\n","    probabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\n","    for i in range(len(class_summaries)):\n","      mean, stdev, _ = class_summaries[i]\n","      probabilities[class_value] *= calculate_probability(row[i], mean, stdev)\n","  return probabilities\n","\n","# Test calculating class probabilities\n","dataset = [[3.393533211,2.331273381,0],\n","  [3.110073483,1.781539638,0],\n","  [1.343808831,3.368360954,0],\n","  [3.582294042,4.67917911,0],\n","  [2.280362439,2.866990263,0],\n","  [7.423436942,4.696522875,1],\n","  [5.745051997,3.533989803,1],\n","  [9.172168622,2.511101045,1],\n","  [7.792783481,3.424088941,1],\n","  [7.939820817,0.791637231,1]]\n","summaries = summarize_by_class(dataset)\n","probabilities = calculate_class_probabilities(summaries, dataset[0])\n","# prints the probabilities calculated for each class.\n","print(probabilities) \n","# Since 0.05 > 0.0001, therefore we could conclude class = 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PzdYA2zxeIt4","executionInfo":{"status":"ok","timestamp":1682997718042,"user_tz":-480,"elapsed":424,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"7cdb8b82-8d91-4a03-c65e-0988626ffbce"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["{0: 0.05032427673372076, 1: 0.00011557718379945765}\n"]}]},{"cell_type":"markdown","source":["### Iris Flower Species Case Study"],"metadata":{"id":"VRz2zqcqfK7L"}},{"cell_type":"code","source":["# Naive Bayes On The Iris Dataset\n","from csv import reader\n","from random import seed\n","from random import randrange\n","from math import sqrt\n","from math import exp\n","from math import pi\n","\n","# Load a CSV file\n","def load_csv(filename):\n","  dataset = list()\n","  with open(filename, 'r') as file:\n","    csv_reader = reader(file)\n","    for row in csv_reader:\n","      if not row:\n","        continue\n","      dataset.append(row)\n","  return dataset\n","\n","# Convert string column to float\n","def str_column_to_float(dataset, column):\n","  for row in dataset:\n","    row[column] = float(row[column].strip())\n","\n","# Convert string column to integer\n","def str_column_to_int(dataset, column):\n","  class_values = [row[column] for row in dataset]\n","  unique = set(class_values)\n","  lookup = dict()\n","  for i, value in enumerate(unique):\n","    lookup[value] = i\n","  for row in dataset:\n","    row[column] = lookup[row[column]]\n","  return lookup\n","\n","# Split a dataset into k folds\n","def cross_validation_split(dataset, n_folds):\n","  dataset_split = list()\n","  dataset_copy = list(dataset)\n","  fold_size = int(len(dataset) / n_folds)\n","  for _ in range(n_folds):\n","    fold = list()\n","    while len(fold) < fold_size:\n","      index = randrange(len(dataset_copy))\n","      fold.append(dataset_copy.pop(index))\n","    dataset_split.append(fold)\n","  return dataset_split\n","\n","# Calculate accuracy percentage\n","def accuracy_metric(actual, predicted):\n","  correct = 0\n","  for i in range(len(actual)):\n","    if actual[i] == predicted[i]:\n","      correct += 1\n","  return correct / float(len(actual)) * 100.0\n","\n","# Evaluate an algorithm using a cross validation split\n","def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n","  folds = cross_validation_split(dataset, n_folds)\n","  scores = list()\n","  for fold in folds:\n","    train_set = list(folds)\n","    train_set.remove(fold)\n","    train_set = sum(train_set, [])\n","    test_set = list()\n","    for row in fold:\n","      row_copy = list(row)\n","      test_set.append(row_copy)\n","      row_copy[-1] = None\n","    predicted = algorithm(train_set, test_set, *args)\n","    actual = [row[-1] for row in fold]\n","    accuracy = accuracy_metric(actual, predicted)\n","    scores.append(accuracy)\n","  return scores\n","\n","# Split the dataset by class values, returns a dictionary\n","def separate_by_class(dataset):\n","  separated = dict()\n","  for i in range(len(dataset)):\n","    vector = dataset[i]\n","    class_value = vector[-1]\n","    if (class_value not in separated):\n","      separated[class_value] = list()\n","    separated[class_value].append(vector)\n","  return separated\n","\n","# Calculate the mean of a list of numbers\n","def mean(numbers):\n","  return sum(numbers)/float(len(numbers))\n","\n","# Calculate the standard deviation of a list of numbers\n","def stdev(numbers):\n","  avg = mean(numbers)\n","  variance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\n","  return sqrt(variance)\n","\n","# Calculate the mean, stdev and count for each column in a dataset\n","def summarize_dataset(dataset):\n","  summaries = [(mean(column), stdev(column), len(column)) for column in zip(*dataset)]\n","  del(summaries[-1])\n","  return summaries\n","\n","# Split dataset by class then calculate statistics for each row\n","def summarize_by_class(dataset):\n","  separated = separate_by_class(dataset)\n","  summaries = dict()\n","  for class_value, rows in separated.items():\n","    summaries[class_value] = summarize_dataset(rows)\n","  return summaries\n","\n","# Calculate the Gaussian probability distribution function for x\n","def calculate_probability(x, mean, stdev):\n","  exponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n","  return (1 / (sqrt(2 * pi) * stdev)) * exponent\n","\n","# Calculate the probabilities of predicting each class for a given row\n","def calculate_class_probabilities(summaries, row):\n","  total_rows = sum([summaries[label][0][2] for label in summaries])\n","  probabilities = dict()\n","  for class_value, class_summaries in summaries.items():\n","    probabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\n","    for i in range(len(class_summaries)):\n","      mean, stdev, _ = class_summaries[i]\n","      probabilities[class_value] *= calculate_probability(row[i], mean, stdev)\n","  return probabilities\n","\n","# Predict the class for a given row\n","def predict(summaries, row):\n","  probabilities = calculate_class_probabilities(summaries, row)\n","  best_label, best_prob = None, -1\n","  for class_value, probability in probabilities.items():\n","    if best_label is None or probability > best_prob:\n","      best_prob = probability\n","      best_label = class_value\n","  return best_label\n","\n","# Naive Bayes Algorithm\n","def naive_bayes(train, test):\n","  summarize = summarize_by_class(train)\n","  predictions = list()\n","  for row in test:\n","    output = predict(summarize, row)\n","    predictions.append(output)\n","  return(predictions)\n","\n","# Test Naive Bayes on Iris Dataset\n","seed(1)\n","filename = 'iris.csv'\n","dataset = load_csv(filename)\n","for i in range(len(dataset[0])-1):\n","  str_column_to_float(dataset, i)\n","\n","# convert class column to integers\n","str_column_to_int(dataset, len(dataset[0])-1)\n","\n","# evaluate algorithm\n","n_folds = 5\n","scores = evaluate_algorithm(dataset, naive_bayes, n_folds)\n","print('Scores: %s' % scores)\n","print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oBIhbe_lfP2U","executionInfo":{"status":"ok","timestamp":1682998222187,"user_tz":-480,"elapsed":753,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"8dcefd29-2bd1-461f-ab3c-c8078f534d30"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Scores: [93.33333333333333, 96.66666666666667, 100.0, 93.33333333333333, 93.33333333333333]\n","Mean Accuracy: 95.333%\n"]}]}]}