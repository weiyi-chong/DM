{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMEpeJNVtWZdmvvyICTahfX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Improve Performance with Ensembles (B2C15)\n","- boost the accuracy in dataset"],"metadata":{"id":"2r5ATFPSkBtV"}},{"cell_type":"markdown","source":["## 15.1 Combine Models into Ensemble Prediction\n","- Bagging - Building multiple models (typically of the same type) from different subsamples\n","of the training dataset.\n","- Boosting. Building multiple models (typically of the same type) each of which learns to\n","fix the prediction errors of a prior model in the sequence of models.\n","- Voting. Building multiple models (typically of differing types) and simple statistics (like\n","calculating the mean) are used to combine predictions."],"metadata":{"id":"4xFvhNoskPM3"}},{"cell_type":"markdown","source":["###15.2 Bagging\n","Performs best with algorithms than have high variance\n","- Bagged Decision Trees\n","- Random Forest\n","- Extra Trees"],"metadata":{"id":"w85NEyFfkpwL"}},{"cell_type":"markdown","source":["15.2.1 Bagged Decision Tree"],"metadata":{"id":"tGqUXjZBkx9E"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vFNEb1pOj9w_","executionInfo":{"status":"ok","timestamp":1683000408996,"user_tz":-480,"elapsed":6634,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"c23ff927-2692-488f-b897-a848c4c2ce9c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["0.7578263841421736\n"]}],"source":["# Bagged Decision Trees for Classification\n","from pandas import read_csv\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","filename = 'pima-indians-diabetes.csv'\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = read_csv(filename, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","seed = 7\n","kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n","cart = DecisionTreeClassifier()\n","num_trees = 100\n","model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=seed)\n","results = cross_val_score(model, X, Y, cv=kfold)\n","print(results.mean())"]},{"cell_type":"markdown","source":["15.2.2 Random Forest\n","- Extension of bagged decision tree\n","- rather than greedily choosing the best split point in\n","the construction of each tree, only a random subset of features are considered for each split."],"metadata":{"id":"kq9BxK5gmhTU"}},{"cell_type":"code","source":["# Random Forest Classification\n","from pandas import read_csv\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.ensemble import RandomForestClassifier\n","filename = 'pima-indians-diabetes.csv'\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = read_csv(filename, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","num_trees = 100\n","max_features = 3\n","kfold = KFold(n_splits=10,  shuffle= True, random_state=7)\n","model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n","results = cross_val_score(model, X, Y, cv=kfold)\n","print(results.mean())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S2NYxJAQmwus","executionInfo":{"status":"ok","timestamp":1683000412847,"user_tz":-480,"elapsed":3855,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"9d236c57-48c5-47c4-8851-24019caf4751"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7578092959671908\n"]}]},{"cell_type":"markdown","source":["15.2.3 Extra Trees"],"metadata":{"id":"QXJ06QrmnFPE"}},{"cell_type":"code","source":["# Extra Trees Classification\n","from pandas import read_csv\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.ensemble import ExtraTreesClassifier\n","filename = 'pima-indians-diabetes.csv'\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = read_csv(filename, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","num_trees = 100\n","max_features = 7\n","kfold = KFold(n_splits=10, shuffle= True, random_state=7)\n","model = ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)\n","results = cross_val_score(model, X, Y, cv=kfold)\n","print(results.mean())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ejw7vMfcnJDT","executionInfo":{"status":"ok","timestamp":1683000414641,"user_tz":-480,"elapsed":1800,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"58143b57-debf-4534-a957-0ac415e979ff"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7681647300068353\n"]}]},{"cell_type":"markdown","source":["###15.3 Boosting Algorithm\n","Creates a sequence of models - attempt to correct the mistakes of the models before them in sequence\n","- AdaBoost\n","- Stochastic Gradient Boosting"],"metadata":{"id":"DU5HUrM5nW8I"}},{"cell_type":"markdown","source":["15.3.1 AdaBoost \n","- weighting instances in dataset by how the difficulty to classify, allowing the algorithm to pay less/more attention to them in the construction of the subsequent models"],"metadata":{"id":"XxU2N_r7n1Fg"}},{"cell_type":"code","source":["from pandas import read_csv\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.ensemble import AdaBoostClassifier\n","filename = 'pima-indians-diabetes.csv'\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = read_csv(filename, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","num_trees = 30\n","seed=7\n","kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n","model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\n","results = cross_val_score(model, X, Y, cv=kfold)\n","print(results.mean())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lj7qCP5WoKDH","executionInfo":{"status":"ok","timestamp":1683000415039,"user_tz":-480,"elapsed":403,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"e268a098-8f42-484d-aa04-ae0802449e80"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7552802460697198\n"]}]},{"cell_type":"markdown","source":["15.3.2 Stochastic Gradient Boosting\n"],"metadata":{"id":"5aoNxgtNoUbL"}},{"cell_type":"code","source":["# Stochastic Gradient Boosting Classification\n","from pandas import read_csv\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.ensemble import GradientBoostingClassifier\n","filename = 'pima-indians-diabetes.csv'\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = read_csv(filename, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","seed = 7\n","num_trees = 100\n","kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n","model = GradientBoostingClassifier(n_estimators=num_trees, random_state=seed)\n","results = cross_val_score(model, X, Y, cv=kfold)\n","print(results.mean())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mYJhiazpoZdR","executionInfo":{"status":"ok","timestamp":1683000416539,"user_tz":-480,"elapsed":1502,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"73c9d476-326a-428f-c4f3-0959bbb60256"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7604921394395079\n"]}]},{"cell_type":"markdown","source":["###15.4 Voting Ensemble\n","combining the predictions from multiple machine learning algorithms."],"metadata":{"id":"hUCUgZg-oehb"}},{"cell_type":"code","source":["# Voting Ensemble for Classification\n","from pandas import read_csv\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","from sklearn.ensemble import VotingClassifier\n","filename = 'pima-indians-diabetes.csv'\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = read_csv(filename, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","kfold = KFold(n_splits=10, shuffle= True, random_state=7)\n","\n","# create the sub models\n","estimators = []\n","model1 = LogisticRegression(solver='liblinear')\n","estimators.append(('logistic', model1))\n","model2 = DecisionTreeClassifier()\n","estimators.append(('cart', model2))\n","model3 = SVC(gamma='auto')\n","estimators.append(('svm', model3))\n","\n","# create the ensemble model\n","ensemble = VotingClassifier(estimators)\n","results = cross_val_score(ensemble, X, Y, cv=kfold)\n","print(results.mean())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"guh6QgGVov0e","executionInfo":{"status":"ok","timestamp":1683000416541,"user_tz":-480,"elapsed":11,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"8e2aec68-2a75-41a5-dd7b-d50c7a757d27"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7514012303485986\n"]}]}]}